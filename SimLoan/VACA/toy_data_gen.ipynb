{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "from sklearn import metrics\n",
    "from functools import wraps\n",
    "from time import time\n",
    "\n",
    "n = 100\n",
    "x_dim = 2\n",
    "hiddens = [x_dim + 1, 32, 64, 1]\n",
    "test_size = 0.2\n",
    "valid_size = 0.125\n",
    "batch_size = 10\n",
    "seq_len = 10\n",
    "l = 0.1\n",
    "c_hiddens = [x_dim + 1, 32, 64, 1]\n",
    "g_hidden_size = 64\n",
    "g_num_layers = 2\n",
    "d_hidden_size = 64\n",
    "d_num_layers = 2\n",
    "gan_epochs = 3000\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor(x):\n",
    "    return torch.FloatTensor(x)\n",
    "\n",
    "def to_tensor(z, x, y=None):\n",
    "    if torch.is_tensor(x):\n",
    "        zx = torch.cat([z, x], dim=1)\n",
    "    else:\n",
    "        zx = np.concatenate([z, x], axis=1)\n",
    "        zx = torch.FloatTensor(zx)\n",
    "    if isinstance(y, np.ndarray):\n",
    "        y = torch.FloatTensor(y)\n",
    "        return zx, y\n",
    "    return zx\n",
    "\n",
    "class TrueModel(nn.Module):\n",
    "\n",
    "    def __init__(self, hiddens, seed=0):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for in_dim, out_dim in zip(hiddens[:-1], hiddens[1:]):\n",
    "            layers.append(nn.Linear(in_dim, out_dim))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        layers.pop()\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "        self.loss_fn = nn.BCELoss()\n",
    "        self.optim = Adam(self.parameters())\n",
    "\n",
    "    def forward(self, zx):\n",
    "        return self.model(zx)\n",
    "\n",
    "    def predict(self, z, x):\n",
    "        zx = to_tensor(z, x)\n",
    "        pred = self(zx)\n",
    "        pred_y = pred.detach().round().cpu().numpy()\n",
    "        return pred_y\n",
    "\n",
    "    def fit(self, z, x, y, patience=10):\n",
    "        zx, y = to_tensor(z, x, y)\n",
    "\n",
    "        epoch, counter = 0, 0\n",
    "        best_loss = float('inf')\n",
    "        while True:\n",
    "            pred = self(zx)\n",
    "            loss = self.loss_fn(pred, y)\n",
    "\n",
    "            self.optim.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "            \n",
    "            epoch += 1\n",
    "            if loss.item() <= best_loss:\n",
    "                torch.save(self.state_dict(), self.path)\n",
    "                best_loss = loss.item()\n",
    "                counter = 0\n",
    "            else:\n",
    "                counter += 1\n",
    "                if counter == patience:\n",
    "                    break\n",
    "        print(f\"TrueModel Fit Done in {epoch} epochs!\")\n",
    "\n",
    "    def sample(self, s, x, scale=0.8):\n",
    "        sx = to_tensor(s, x)\n",
    "        prob = self(sx)\n",
    "        y = torch.bernoulli(prob * scale)\n",
    "        return y.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demographic_parity(sensi, pred_y):\n",
    "\n",
    "    s0 = sum(sensi.squeeze() == 0)\n",
    "    s1 = sum(sensi.squeeze() == 1)\n",
    "    y0 = sum(pred_y.squeeze() == 0)\n",
    "    y1 = sum(pred_y.squeeze() == 1)\n",
    "    y1_s0 = sum(pred_y[sensi.squeeze() == 0].squeeze() == 1) / s0\n",
    "    y1_s1 = sum(pred_y[sensi.squeeze() == 1].squeeze() == 1) / s1\n",
    "    print(f\"#(S=0): {s0}, #(S=1): {s1}, #(y0): {y0}, #(y1): {y1}, P(y=1|s=0)={y1_s0:.3f}, P(y=1|s=1)={y1_s1:.3f}\")\n",
    "    return y1_s1 - y1_s0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_time(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time()\n",
    "        duration = end_time - start_time\n",
    "        print(f\"Time: {duration:5.2f}s\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, hiddens, dropout_prob = 0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "        for in_dim, out_dim in zip(hiddens[:-1], hiddens[1:]):\n",
    "            layers.append(nn.Linear(in_dim, out_dim))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            layers.append(nn.Dropout(p=dropout_prob))\n",
    "        layers.pop()\n",
    "        layers.append(nn.Sigmoid())\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        self.loss_fn = nn.BCELoss()\n",
    "        self.optim = Adam(self.parameters())\n",
    "\n",
    "        self.dropout_prob = dropout_prob\n",
    "\n",
    "    def get_params(self):\n",
    "        params = []\n",
    "        for param in self.parameters():\n",
    "            params.append(param.detach().cpu().flatten().numpy())\n",
    "        return np.hstack(params)\n",
    "\n",
    "    def forward(self, s_mb, x_mb, num_samples = 10):\n",
    "        pred = []\n",
    "\n",
    "        for _ in range(num_samples):\n",
    "            sx_mb = torch.cat([s_mb, x_mb], dim=1)\n",
    "            output = self.model(sx_mb)\n",
    "            pred.append(output.unsqueeze(0))  # Add the unsqueezed prediction\n",
    "        return  torch.mean(torch.cat(pred, dim=0), dim=0)\n",
    "\n",
    "    def predict(self, s_mb, x_mb):\n",
    "        probs = self(s_mb, x_mb)\n",
    "        pred_y = probs.detach().round().cpu().numpy()\n",
    "        return pred_y\n",
    "\n",
    "    def sample(self, s, x, scale=1.0):\n",
    "        prob = self(s, x)\n",
    "        y = torch.bernoulli(prob * scale)\n",
    "        return y.detach().cpu().numpy()\n",
    "\n",
    "    @count_time\n",
    "    def fit(self, loader, valid_loader, save_path, device, patience=20):\n",
    "        epoch, counter = 0, 0\n",
    "        best_loss = float('inf')\n",
    "\n",
    "        while True:\n",
    "            loss = 0.\n",
    "            for s_mb, x_mb, y_mb in loader:\n",
    "                s_mb = s_mb.to(device)\n",
    "                x_mb = x_mb.to(device)\n",
    "                y_mb = y_mb.to(device)\n",
    "\n",
    "                batch_loss = 0.\n",
    "                for i in range(x_mb.size(1)):\n",
    "                    pred_y_mb = self(s_mb, x_mb[:, i])\n",
    "                    batch_loss += self.loss_fn(pred_y_mb, y_mb[:, i])\n",
    "                loss += batch_loss.item()\n",
    "\n",
    "                self.optim.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                self.optim.step()\n",
    "\n",
    "            epoch += 1\n",
    "            valid_loss = self.eval(valid_loader, device)\n",
    "            if valid_loss <= best_loss:\n",
    "                # torch.save(self.state_dict(), save_path)\n",
    "                best_loss = valid_loss\n",
    "                counter = 0\n",
    "            else:\n",
    "                counter += 1\n",
    "                if counter == patience:\n",
    "                    break\n",
    "            \n",
    "            if epoch == 1 or epoch % 100 == 0:\n",
    "                print(f'{epoch:6.0f} | loss: {loss:6.4f}')\n",
    "        print(f\"Classifier Fit Done in {epoch} epochs!\")\n",
    "\n",
    "    def eval(self, loader, device, verbose=False):\n",
    "        loss = 0.\n",
    "        for s_mb, x_mb, y_mb in loader:\n",
    "            s_mb = s_mb.to(device)\n",
    "            x_mb = x_mb.to(device)\n",
    "            y_mb = y_mb.to(device)\n",
    "\n",
    "            batch_loss = 0.\n",
    "            for i in range(x_mb.size(1)):\n",
    "                pred_y_mb = self(s_mb, x_mb[:, i])\n",
    "                batch_loss += self.loss_fn(pred_y_mb, y_mb[:, i])\n",
    "                loss += batch_loss.item()\n",
    "\n",
    "                if verbose:\n",
    "                    pred_y_mb = self.predict(s_mb, x_mb[:, i])\n",
    "                    true_y_mb = y_mb[:, i].cpu().numpy()\n",
    "                    s_mb_np = s_mb.cpu().numpy()\n",
    "\n",
    "                    acc = metrics.accuracy_score(true_y_mb, pred_y_mb) * 100\n",
    "                    fair = demographic_parity(s_mb_np, pred_y_mb)\n",
    "                    print(f\"Step: {i:6.0f}, ACC: {acc:6.2f}%, FAIR: {fair:6.2f}\\n\")\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_initial_data(n, seed = 0):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    s0 = torch.bernoulli(torch.empty(n,1).uniform_(0,1)).numpy()\n",
    "    x0 = np.random.randn(n, 1) + np.sin(s0)\n",
    "    z0 = np.cos(x0) + np.random.randn(n, 1) + np.sin(s0)\n",
    "    y = torch.bernoulli(torch.from_numpy(1 /(1+  np.exp(-x0 +z0))))\n",
    "    return torch.from_numpy(s0), to_tensor(x0, z0), y\n",
    "\n",
    "def sequential_data(s0, x0, y0, seq_len, hiddens, l, seed=0):\n",
    "    n = s0.size()[0]\n",
    "    model = TrueModel(hiddens, seed)\n",
    "    sx = to_tensor(s0, x0)\n",
    "    sx.requires_grad = True\n",
    "    sx = sx.to(dtype=torch.float32)\n",
    "    prob = model(sx)\n",
    "    loss = nn.BCELoss()(prob, torch.ones_like(prob))\n",
    "    loss.backward()\n",
    "    x = x0\n",
    "    y= y0\n",
    "    prevx = x.numpy()\n",
    "    prevy = y\n",
    "    s0 = s0.numpy()\n",
    "    nx = np.empty_like(s0)\n",
    "    nz = np.empty_like(s0)\n",
    "    ny = np.empty_like(s0)\n",
    "    for i in range(1, seq_len):\n",
    "        loss = nn.BCELoss()(prob, torch.ones_like(prob))\n",
    "        delta_y = prevy*loss\n",
    "        for j in range(n):\n",
    "            nx[j] = np.random.randn() + np.sin(s0[j]) + l*(prevx[j][0] - int(delta_y[j]))\n",
    "            nz[j] = np.cos(nx[j]) + np.random.randn() + np.sin(s0[j])  + l*(prevx[j][1] - int(delta_y[j]))\n",
    "        ny = torch.bernoulli(torch.from_numpy(1 /(1+  np.exp(-nx +nz))))\n",
    "        prevx = to_tensor(nx, nz)\n",
    "        x = torch.cat((x, prevx),0)\n",
    "        y = torch.cat((y, ny),0)\n",
    "        prevx = prevx.numpy()\n",
    "        prevy = ny\n",
    "    # x = np.array(x, dtype=np.float32).reshape((n, seq_len, 2))\n",
    "    #y = np.array(y, dtype=np.int32).reshape(n, seq_len, 1)\n",
    "    return x, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0, x0, y0 = gen_initial_data(n,0)\n",
    "x, y = sequential_data(s0, x0, y0, seq_len, hiddens, l, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x01 = []\n",
    "z01 = []\n",
    "z00 = []\n",
    "x00 = []\n",
    "x10 = []\n",
    "z10 = []\n",
    "x11 = []\n",
    "z11 = []\n",
    "s_temp = np.array(s0)\n",
    "for i in range(n):\n",
    "    if y[i] == 1 and s_temp[i % n] == 1:\n",
    "        x11.append(x[i][0])\n",
    "        z11.append(x[i][1])\n",
    "    elif y[i] == 1 and s_temp[i % n] == 0:\n",
    "        x01.append(x[i][0])\n",
    "        z01.append(x[i][1])\n",
    "    elif y[i] == 0 and s_temp[i % n] == 1:\n",
    "        x10.append(x[i][0])\n",
    "        z10.append(x[i][1])\n",
    "    else:\n",
    "        x00.append(x[i][0])\n",
    "        z00.append(x[i][1])\n",
    "\n",
    "\n",
    "fig_start = plt.figure()\n",
    "ax = fig_start.gca()\n",
    "\n",
    "ax.scatter(x00, z00, marker = 'x', color = 'red')\n",
    "ax.scatter(x11, z11, marker = 'o', color = 'blue')\n",
    "ax.scatter(x01, z01, marker = 'x', color = 'blue')\n",
    "ax.scatter(x10, z10, marker = 'o', color = 'red')\n",
    "\n",
    "x01 = []\n",
    "z01 = []\n",
    "z00 = []\n",
    "x00 = []\n",
    "x10 = []\n",
    "z10 = []\n",
    "x11 = []\n",
    "z11 = []\n",
    "\n",
    "for i in range(3*n, 4*n):\n",
    "    if y[i] == 1 and s_temp[i % 100] == 1:\n",
    "        x11.append(x[i][0])\n",
    "        z11.append(x[i][1])\n",
    "    elif y[i] == 1 and s_temp[i % 100] == 0:\n",
    "        x01.append(x[i][0])\n",
    "        z01.append(x[i][1])\n",
    "    elif y[i] == 0 and s_temp[i % 100] == 1:\n",
    "        x10.append(x[i][0])\n",
    "        z10.append(x[i][1])\n",
    "    else:\n",
    "        x00.append(x[i][0])\n",
    "        z00.append(x[i][1])\n",
    "\n",
    "\n",
    "fig_m = plt.figure()\n",
    "axm = fig_m.gca()\n",
    "\n",
    "axm.scatter(x00, z00, marker = 'x', color = 'red')\n",
    "axm.scatter(x11, z11, marker = 'o', color = 'blue')\n",
    "axm.scatter(x01, z01, marker = 'x', color = 'blue')\n",
    "axm.scatter(x10, z10, marker = 'o', color = 'red')\n",
    "\n",
    "x01 = []\n",
    "z01 = []\n",
    "z00 = []\n",
    "x00 = []\n",
    "x10 = []\n",
    "z10 = []\n",
    "x11 = []\n",
    "z11 = []\n",
    "\n",
    "for i in range(9*n, 10*n):\n",
    "    if y[i] == 1 and s_temp[i % n] == 1:\n",
    "        x11.append(x[i][0])\n",
    "        z11.append(x[i][1])\n",
    "    elif y[i] == 1 and s_temp[i % n] == 0:\n",
    "        x01.append(x[i][0])\n",
    "        z01.append(x[i][1])\n",
    "    elif y[i] == 0 and s_temp[i % n] == 1:\n",
    "        x10.append(x[i][0])\n",
    "        z10.append(x[i][1])\n",
    "    else:\n",
    "        x00.append(x[i][0])\n",
    "        z00.append(x[i][1])\n",
    "\n",
    "\n",
    "fig_f = plt.figure()\n",
    "axf = fig_f.gca()\n",
    "\n",
    "axf.scatter(x00, z00, marker = 'x', color = 'red', label='s=0, y=0')\n",
    "axf.scatter(x11, z11, marker = 'o', color = 'blue', label='s=1, y=1')\n",
    "axf.scatter(x01, z01, marker = 'x', color = 'blue', label='s=0, y=1')\n",
    "axf.scatter(x10, z10, marker = 'o', color = 'red', label='s=1, y=0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = np.array(x, dtype=np.float32).reshape((100, seq_len, 2))\n",
    "y = np.array(y, dtype=np.int32).reshape(100, seq_len, 1)\n",
    "s0 = np.array(s0)\n",
    "s_train, s_test, x_train, x_test, y_train, y_test = train_test_split(s0, x, y, test_size=test_size, random_state=10)\n",
    "s_train, s_valid, x_train, x_valid, y_train, y_valid = train_test_split(s_train, x_train, y_train, test_size=valid_size, random_state=10)\n",
    "print(x_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, in_size, hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.h0_linear = nn.Linear(in_size, hidden_size)\n",
    "        self.rnn = nn.GRU(in_size + 3, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, in_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x0, noise, s0, clf):\n",
    "        ss = torch.clone(s0)\n",
    "        ss = ss.to(x0.device)\n",
    "        s0 = torch.zeros(s0.size(0), 2).scatter_(1, s0.long(), torch.ones_like(s0))\n",
    "        s0 = s0.to(x0.device)\n",
    "\n",
    "        h0 = self.h0_linear(x0)\n",
    "        h0 = h0.unsqueeze(0).repeat(self.num_layers, 1, 1)\n",
    "        yt = clf(ss, x0)\n",
    "        \n",
    "        xs, ys = [x0], [yt]\n",
    "        for i in range(noise.size(1)):\n",
    "            \n",
    "            y_noise = torch.cat([s0, yt, noise[:, i]], dim=-1).unsqueeze(1)\n",
    "            output, h0 = self.rnn(y_noise, h0)\n",
    "            # xt = self.sigmoid(self.linear(output).squeeze())\n",
    "            xt = self.linear(output).squeeze()\n",
    "            yt = clf(ss, xt)\n",
    "\n",
    "            xs.append(xt)\n",
    "            ys.append(yt)\n",
    "\n",
    "        xs = torch.stack(xs, dim=1)\n",
    "        ys = torch.stack(ys, dim=1)\n",
    "        return xs, ys, ys.round().detach()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, in_size, hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rnn = nn.GRU(in_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, hn = self.rnn(x)\n",
    "        output = self.linear(output)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class DistributionDiscriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, hiddens):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "        for in_dim, out_dim in zip(hiddens[:-1], hiddens[1:]):\n",
    "            layers.append(nn.Linear(in_dim, out_dim))\n",
    "            layers.append(nn.LeakyReLU(0.2))\n",
    "        layers.pop()\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Classifier(c_hiddens)\n",
    "generator = Generator(x_dim, g_hidden_size, g_num_layers)\n",
    "generator.to(device)\n",
    "discriminator = Discriminator(x_dim, d_hidden_size, d_num_layers)\n",
    "discriminator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, RMSprop\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "def train_discriminator(clf, G, D, optim, loss_fn, xs, zs, ss):\n",
    "    xs_fake, _, _ = G(xs[:, 0], zs, ss, clf)\n",
    "    fake = D(xs_fake.detach())\n",
    "    loss_fake = loss_fn(fake, torch.zeros_like(fake))\n",
    "\n",
    "    real = D(xs)\n",
    "    loss_real = loss_fn(real, torch.ones_like(real))\n",
    "\n",
    "    loss = loss_fake + loss_real\n",
    "\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def get_moment_loss(x_pred, x_true):\n",
    "    m1 = torch.mean(torch.abs(x_pred.mean(dim=0) - x_true.mean(dim=0)))\n",
    "    m2 = torch.mean(torch.abs(\n",
    "        torch.sqrt(x_pred.var(dim=0, unbiased=False) + 1e-6) -\n",
    "        torch.sqrt(x_true.var(dim=0, unbiased=False) + 1e-6)\n",
    "    ))\n",
    "    return m1 + m2\n",
    "\n",
    "\n",
    "def train_generator(clf, G, D, optim, loss_fn, xs, zs, ss, gamma=100):\n",
    "    xs_fake, _, _ = G(xs[:, 0], zs, ss, clf)\n",
    "    fake = D(xs_fake)\n",
    "\n",
    "    loss1 = loss_fn(fake, torch.ones_like(fake))\n",
    "    loss2 = get_moment_loss(xs_fake, xs)\n",
    "    loss = loss1 + gamma * loss2\n",
    "\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    return loss, loss2\n",
    "\n",
    "\n",
    "@count_time\n",
    "def train_gan(loader, clf, G, D, n_epochs, device):\n",
    "    g_optim = Adam(G.parameters())\n",
    "    d_optim = Adam(D.parameters())\n",
    "    loss_fn = nn.BCELoss()\n",
    "    hist_mmt = np.empty(0)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        for i, (s_mb, x_mb, y_mb) in enumerate(loader, start=1):\n",
    "            batch, seq, dim = x_mb.size()\n",
    "            x_mb = x_mb.to(device)\n",
    "            z_mb = torch.rand(batch, seq-1, dim).to(device)\n",
    "\n",
    "            for _ in range(2):\n",
    "                g_loss, mmt_loss = train_generator(clf, G, D, g_optim, loss_fn, x_mb, z_mb, s_mb)\n",
    "                hist_mmt = np.append(hist_mmt, float(mmt_loss))\n",
    "\n",
    "            for _ in range(1):\n",
    "                d_loss = train_discriminator(clf, G, D, d_optim, loss_fn, x_mb, z_mb, s_mb)\n",
    "\n",
    "            step = epoch * len(loader) + i\n",
    "            if step % 1000 == 0:\n",
    "                print(f'Epoch: {epoch: 6.0f} | step: {step:6.0f} | d_loss: {d_loss:6.4f} | g_loss: {g_loss: 6.4f} | mmt_loss: {mmt_loss:6.4f}')\n",
    "\n",
    "    hist_mmt = np.asarray(hist_mmt)\n",
    "    plt.plot(np.arange(0, len(hist_mmt), 1), hist_mmt)\n",
    "    # plt.plot(np.arange(0, len(hist_mmt) + 1, 1), np.arange(0, len(hist_mmt) + 1, 1))\n",
    "\n",
    "    \n",
    "            \n",
    "\n",
    "\n",
    "def generate_dataset_from_gan(loader, clf, G, device, extra_seq=0):\n",
    "    gen_s, gen_x, gen_y = [], [], []\n",
    "\n",
    "    batch_size = None\n",
    "    for s_mb, x_mb, y_mb in loader:\n",
    "        batch, seq_len, x_dim = x_mb.shape\n",
    "        if batch_size is None:\n",
    "            batch_size = batch\n",
    "\n",
    "        x_mb = x_mb.to(device)\n",
    "        z_mb = torch.randn(batch, seq_len + extra_seq - 1, x_dim).to(device)\n",
    "\n",
    "        gen_x_mb, _, gen_y_mb = G(x_mb[:, 0], z_mb, s_mb, clf)\n",
    "        \n",
    "        gen_s.append(s_mb)\n",
    "        gen_x.append(gen_x_mb)\n",
    "        gen_y.append(gen_y_mb)\n",
    "\n",
    "    gen_s = torch.cat(gen_s, dim=0).detach().cpu().numpy()\n",
    "    gen_x = torch.cat(gen_x, dim=0).detach().cpu().numpy()\n",
    "    gen_y = torch.cat(gen_y, dim=0).detach().cpu().numpy()\n",
    "\n",
    "    gen_data = TensorDataset(tensor(gen_s), tensor(gen_x), tensor(gen_y))\n",
    "    gen_loader = DataLoader(gen_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return gen_loader, gen_s, gen_x, gen_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "res_path = Path('../res')\n",
    "log_dir = res_path / f'experiments_{1}'\n",
    "clf_path = log_dir / (f\"c_model_\" + \".pth\")\n",
    "gan_path = log_dir / (f\"gan_model_\" + str(gan_epochs) + \"_\" + str(g_hidden_size) + \".pth\")\n",
    "re_clf_path = log_dir / (f\"dp_model-\" + str(6)+ \".pth\")\n",
    "tsne_path = log_dir / (f\"syn-tsne.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "train_data = TensorDataset(tensor(s_train), tensor(x_train), tensor(y_train))\n",
    "valid_data = TensorDataset(tensor(s_valid), tensor(x_valid),tensor(y_valid))\n",
    "test_data = TensorDataset(tensor(s_test), tensor(x_test), tensor(y_test))\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
    "valid_loader = DataLoader(valid_data, batch_size=len(valid_data), shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=len(test_data), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(train_loader, valid_loader, clf_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.eval(test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gan_path.exists():\n",
    "    generator.load_state_dict(torch.load(gan_path, map_location=device))\n",
    "else:\n",
    "    train_gan(train_loader, clf, generator, discriminator, gan_epochs, device)\n",
    "    torch.save(generator.state_dict(), gan_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train_loader, gen_train_s, gen_train_x, gen_train_y = generate_dataset_from_gan(train_loader, clf, generator, device)\n",
    "gen_valid_loader, gen_valid_s, gen_valid_x, gen_valid_y = generate_dataset_from_gan(valid_loader, clf, generator, device)\n",
    "gen_test_loader, gen_test_s, gen_test_x, gen_test_y = generate_dataset_from_gan(test_loader, clf, generator, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vars = gen_train_x[:,:,0]\n",
    "z_vars = gen_train_x[:,:,1]\n",
    "y_vars = gen_train_y[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x01 = []\n",
    "z01 = []\n",
    "z00 = []\n",
    "x00 = []\n",
    "x10 = []\n",
    "z10 = []\n",
    "x11 = []\n",
    "z11 = []\n",
    "\n",
    "for i in range(70):\n",
    "    if gen_train_y[i][0][0] == 1 and gen_train_s[i][0] == 1:\n",
    "        x11.append(x_vars[i][0])\n",
    "        z11.append(z_vars[i][0])\n",
    "    elif gen_train_y[i][0][0] == 1 and gen_train_s[i][0] == 0:\n",
    "        x01.append(x_vars[i][0])\n",
    "        z01.append(z_vars[i][0])\n",
    "    elif gen_train_y[i][0][0] == 0 and gen_train_s[i][0] == 1:\n",
    "        x10.append(x_vars[i][0])\n",
    "        z10.append(z_vars[i][0])\n",
    "    else:\n",
    "        x00.append(x_vars[i][0])\n",
    "        z00.append(z_vars[i][0])\n",
    "\n",
    "fig_start = plt.figure()\n",
    "ax = fig_start.gca()\n",
    "\n",
    "ax.scatter(x00, z00, marker = 'x', color = 'red', label='s=0, y=0')\n",
    "ax.scatter(x11, z11, marker = 'o', color = 'blue', label='s=1, y=1')\n",
    "ax.scatter(x01, z01, marker = 'x', color = 'blue', label='s=0, y=1')\n",
    "ax.scatter(x10, z10, marker = 'o', color = 'red', label='s=1, y=0')\n",
    "\n",
    "x01 = []\n",
    "z01 = []\n",
    "z00 = []\n",
    "x00 = []\n",
    "x10 = []\n",
    "z10 = []\n",
    "x11 = []\n",
    "z11 = []\n",
    "\n",
    "for i in range(70):\n",
    "    if gen_train_y[i][3][0] == 1 and gen_train_s[i][0] == 1:\n",
    "        x11.append(x_vars[i][3])\n",
    "        z11.append(z_vars[i][3])\n",
    "    elif gen_train_y[i][3][0] == 1 and gen_train_s[i][0] == 0:\n",
    "        x01.append(x_vars[i][3])\n",
    "        z01.append(z_vars[i][3])\n",
    "    elif gen_train_y[i][3][0] == 0 and gen_train_s[i][0] == 1:\n",
    "        x10.append(x_vars[i][3])\n",
    "        z10.append(z_vars[i][3])\n",
    "    else:\n",
    "        x00.append(x_vars[i][3])\n",
    "        z00.append(z_vars[i][3])\n",
    "\n",
    "fig_m = plt.figure()\n",
    "axm = fig_m.gca()\n",
    "\n",
    "axm.scatter(x00, z00, marker = 'x', color = 'red', label='s=0, y=0')\n",
    "axm.scatter(x11, z11, marker = 'o', color = 'blue', label='s=1, y=1')\n",
    "axm.scatter(x01, z01, marker = 'x', color = 'blue', label='s=0, y=1')\n",
    "axm.scatter(x10, z10, marker = 'o', color = 'red', label='s=1, y=0')\n",
    "\n",
    "x01 = []\n",
    "z01 = []\n",
    "z00 = []\n",
    "x00 = []\n",
    "x10 = []\n",
    "z10 = []\n",
    "x11 = []\n",
    "z11 = []\n",
    "\n",
    "for i in range(70):\n",
    "    if gen_train_y[i][9][0] == 1 and gen_train_s[i][0] == 1:\n",
    "        x11.append(x_vars[i][9])\n",
    "        z11.append(z_vars[i][9])\n",
    "    elif gen_train_y[i][9][0] == 1 and gen_train_s[i][0] == 0:\n",
    "        x01.append(x_vars[i][9])\n",
    "        z01.append(z_vars[i][9])\n",
    "    elif gen_train_y[i][9][0] == 0 and gen_train_s[i][0] == 1:\n",
    "        x10.append(x_vars[i][9])\n",
    "        z10.append(z_vars[i][9])\n",
    "    else:\n",
    "        x00.append(x_vars[i][9])\n",
    "        z00.append(z_vars[i][9])\n",
    "\n",
    "fig_f = plt.figure()\n",
    "axf = fig_f.gca()\n",
    "\n",
    "axf.scatter(x00, z00, marker = 'x', color = 'red', label='s=0, y=0')\n",
    "axf.scatter(x11, z11, marker = 'o', color = 'blue', label='s=1, y=1')\n",
    "axf.scatter(x01, z01, marker = 'x', color = 'blue', label='s=0, y=1')\n",
    "axf.scatter(x10, z10, marker = 'o', color = 'red', label='s=1, y=0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_real_f = []\n",
    "z_real_f = []\n",
    "\n",
    "for i in range(70):\n",
    "    x_real_f.append(x_train[i][9][0])\n",
    "    z_real_f.append(x_train[i][9][1])\n",
    "\n",
    "x_gan_f = []\n",
    "z_gan_f = []\n",
    "for i in range(70):\n",
    "    x_gan_f.append(x_vars[i][9])\n",
    "    z_gan_f.append(z_vars[i][9])\n",
    "\n",
    "fig_f = plt.figure()\n",
    "axf = fig_f.gca()\n",
    "\n",
    "axf.scatter(x_real_f, z_real_f, color = 'blue')\n",
    "axf.scatter(x_gan_f, z_gan_f, color = 'orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_real_f = x_train[:, :, 0]\n",
    "z_real_f = x_train[:, :, 1]\n",
    "\n",
    "fig_f = plt.figure()\n",
    "axf = fig_f.gca()\n",
    "\n",
    "axf.scatter(x_real_f, z_real_f, color = 'blue')\n",
    "axf.scatter(x_vars, z_vars, color = 'orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate generated training data into sequential step-wise pairs i.e. t0-t1, t1-t2, t2-t3, etc.\n",
    "pairs = np.empty((0, 7))\n",
    "\n",
    "for i in range(gen_train_x.shape[0]):\n",
    "    temp_pair = np.empty((1, 5 + 2*(gen_train_x.shape[2] - 1)))\n",
    "    temp_pair[0, 0] = gen_train_s[i][0]\n",
    "    for j in range(gen_train_x.shape[1] - 1):\n",
    "        for k in range(gen_train_x[0][0].shape[0]):\n",
    "            temp_pair[0, 1+k] = gen_train_x[i, j, k]\n",
    "        temp_pair[0, 1+gen_train_x.shape[2]] = gen_train_y[i, j][0]\n",
    "        for k in range(gen_train_x[0][0].shape[0]):\n",
    "            temp_pair[0, 2 + gen_train_x.shape[2] + k] = gen_train_x[i, j+1, k]\n",
    "        temp_pair[0, 5 + 2*(gen_train_x.shape[2] - 1) - 1] = gen_train_y[i, j+1][0]\n",
    "        pairs = np.vstack([pairs, temp_pair])\n",
    "\n",
    "print(len(pairs))\n",
    "\n",
    "for i in range(gen_valid_x.shape[0]):\n",
    "    temp_pair = np.empty((1, 5 + 2*(gen_valid_x.shape[2] - 1)))\n",
    "    temp_pair[0, 0] = gen_valid_s[i][0]\n",
    "    for j in range(gen_valid_x.shape[1] - 1):\n",
    "        for k in range(gen_valid_x[0][0].shape[0]):\n",
    "            temp_pair[0, 1+k] = gen_valid_x[i, j, k]\n",
    "        temp_pair[0, 1+gen_valid_x.shape[2]] = gen_valid_y[i, j][0]\n",
    "        for k in range(gen_valid_x[0][0].shape[0]):\n",
    "            temp_pair[0, 2 + gen_valid_x.shape[2] + k] = gen_valid_x[i, j+1, k]\n",
    "        temp_pair[0, 5 + 2*(gen_valid_x.shape[2] - 1) - 1] = gen_valid_y[i, j+1][0]\n",
    "        pairs = np.vstack([pairs, temp_pair])\n",
    "\n",
    "print(len(pairs))\n",
    "\n",
    "for i in range(gen_test_x.shape[0]):\n",
    "    temp_pair = np.empty((1, 5 + 2*(gen_test_x.shape[2] - 1)))\n",
    "    temp_pair[0, 0] = gen_test_s[i][0]\n",
    "    for j in range(gen_test_x.shape[1] - 1):\n",
    "        for k in range(gen_test_x[0][0].shape[0]):\n",
    "            temp_pair[0, 1+k] = gen_test_x[i, j, k]\n",
    "        temp_pair[0, 1+gen_test_x.shape[2]] = gen_test_y[i, j][0]\n",
    "        for k in range(gen_test_x[0][0].shape[0]):\n",
    "            temp_pair[0, 2 + gen_test_x.shape[2] + k] = gen_test_x[i, j+1, k]\n",
    "        temp_pair[0, 5 + 2*(gen_test_x.shape[2] - 1) - 1] = gen_test_y[i, j+1][0]\n",
    "        pairs = np.vstack([pairs, temp_pair])\n",
    "\n",
    "print(len(pairs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(pairs)\n",
    "df = df.set_axis(['s', 'x1', 'z1', 'y1', 'x2', 'z2', 'y2'], axis=1)\n",
    "df.to_csv('pairs.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.toy import ToySCM\n",
    "from models.vaca import VACA\n",
    "import utils.args_parser  as argtools\n",
    "from data_modules.het_scm import HeterogeneousSCMDataModule\n",
    "\n",
    "scm = ToySCM(None, 'train', len(pairs))\n",
    "print(scm.X)\n",
    "model_file =   os.path.join('_params', 'model_vaca.yaml')\n",
    "trainer_file =   os.path.join('_params', 'trainer.yaml')\n",
    "\n",
    "cfg = argtools.parse_args(model_file)\n",
    "cfg.update(argtools.parse_args(trainer_file))\n",
    "\n",
    "cfg['dataset'] = {\n",
    "    'name': 'toy',\n",
    "    'params1': {},\n",
    "    'params2': {}\n",
    "}\n",
    "\n",
    "cfg['dataset']['params1']['batch_size'] = batch_size\n",
    "cfg['dataset']['params1']['num_samples_tr'] = len(pairs)\n",
    "cfg['dataset']['params1']['num_workers'] = 0\n",
    "cfg['dataset']['params1']['equations_type'] = 'non-linear'\n",
    "cfg['dataset']['params1']['normalize'] = 'lik'\n",
    "cfg['dataset']['params1']['lambda_'] = 0.05\n",
    "cfg['dataset']['params1']['data_dir'] = '../Data'\n",
    "\n",
    "dataset_params = cfg['dataset']['params1']\n",
    "data_module = HeterogeneousSCMDataModule(**dataset_params)\n",
    "\n",
    "\n",
    "cfg['model']['params']['is_heterogeneous'] = scm.is_heterogeneous\n",
    "cfg['model']['params']['likelihood_x'] = scm.likelihood_list\n",
    "\n",
    "cfg['model']['params']['num_nodes'] = scm.num_nodes\n",
    "cfg['model']['params']['edge_dim'] = scm.edge_dimension\n",
    "\n",
    "model_params = cfg['model']['params']\n",
    "\n",
    "model_vaca = VACA(**model_params)\n",
    "model_vaca.set_random_train_sampler(data_module.get_random_train_sampler())\n",
    "\n",
    "data_module.train_dataset._create_data()\n",
    "data_module.valid_dataset._create_data()\n",
    "data_module.test_dataset._create_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models._evaluator import MyEvaluator\n",
    "\n",
    "evaluator = MyEvaluator(model=model_vaca,\n",
    "                        intervention_list=data_module.train_dataset.get_intervention_list(),\n",
    "                        scaler=data_module.scaler\n",
    "                        )\n",
    "model_vaca.set_my_evaluator(evaluator=evaluator)\n",
    "\n",
    "assert evaluator is not None\n",
    "is_training = 1\n",
    "del cfg['trainer']['progress_bar_refresh_rate']\n",
    "del cfg['trainer']['flush_logs_every_n_steps']\n",
    "del cfg['trainer']['terminate_on_nan']\n",
    "del cfg['trainer']['auto_select_gpus']\n",
    "del cfg['trainer']['weights_summary']\n",
    "cfg['trainer']['enable_model_summary'] = True\n",
    "del cfg['trainer']['gpus']\n",
    "del cfg['trainer']['track_grad_norm']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cfg['trainer']['track_grad_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save dir: exper_test\\toy_\\vaca\\dgnn_elbo_8_8_16_4_normal_0.0_0.2_0.0_0.0_0_False_DeltaLikelihood()_7_21\\adam\\0.005_0.9_0.999_1.2e-06_exp_lr_0.99\\9\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.loggers.tensorboard import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "yaml_file = ''\n",
    "if yaml_file == '':\n",
    "        save_dir = argtools.mkdir(os.path.join(cfg['root_dir'],\n",
    "                                               argtools.get_experiment_folder(cfg),\n",
    "                                               str(cfg['seed'])))\n",
    "else:\n",
    "        save_dir = os.path.join(yaml_file.split('/')[:-1])\n",
    "print(f'Save dir: {save_dir}')\n",
    "# trainer = pl.Trainer(**cfg['model'])\n",
    "logger = TensorBoardLogger(save_dir=save_dir, name='logs', default_hp_metric=False)\n",
    "out = logger.log_hyperparams(argtools.flatten_cfg(cfg))\n",
    "\n",
    "save_dir_ckpt = argtools.mkdir(os.path.join(save_dir, 'ckpt'))\n",
    "ckpt_file = argtools.newest(save_dir_ckpt)\n",
    "callbacks = []\n",
    "if is_training == 1:\n",
    "\n",
    "    checkpoint = ModelCheckpoint(monitor=model_vaca.monitor(),\n",
    "                                     mode=model_vaca.monitor_mode(),\n",
    "                                     save_top_k=1,\n",
    "                                     save_last=True,\n",
    "                                     filename='checkpoint-{epoch:02d}',\n",
    "                                     dirpath=save_dir_ckpt)\n",
    "\n",
    "    callbacks = [checkpoint]\n",
    "\n",
    "    if cfg['early_stopping']:\n",
    "            early_stopping = EarlyStopping(model_vaca.monitor(), mode=model_vaca.monitor_mode(), min_delta=0.0,\n",
    "                                           patience=50)\n",
    "            callbacks.append(early_stopping)\n",
    "\n",
    "    if ckpt_file is not None:\n",
    "            print(f'Loading model training: {ckpt_file}')\n",
    "            trainer = pl.Trainer(logger=logger, callbacks=callbacks, resume_from_checkpoint=ckpt_file,\n",
    "                                 **cfg['trainer'], devices=[0], accelerator='gpu')\n",
    "    else:\n",
    "\n",
    "            trainer = pl.Trainer(logger=logger, callbacks=callbacks, **cfg['trainer'], devices='auto', accelerator='auto')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
