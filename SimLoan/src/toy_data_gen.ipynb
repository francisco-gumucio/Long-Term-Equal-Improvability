{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "x_dim = 2\n",
    "hiddens = [x_dim + 1, 32, 64, 1]\n",
    "test_size = 0.2\n",
    "valid_size = 0.125\n",
    "batch_size = 10\n",
    "seq_len = 10\n",
    "l = 0.1\n",
    "c_hiddens = [x_dim + 1, 32, 64, 1]\n",
    "g_hidden_size = 64\n",
    "g_num_layers = 2\n",
    "d_hidden_size = 64\n",
    "d_num_layers = 2\n",
    "gan_epochs = 3000\n",
    "\n",
    "def to_tensor(z, x, y=None):\n",
    "    if torch.is_tensor(x):\n",
    "        zx = torch.cat([z, x], dim=1)\n",
    "    else:\n",
    "        zx = np.concatenate([z, x], axis=1)\n",
    "        zx = torch.FloatTensor(zx)\n",
    "    if isinstance(y, np.ndarray):\n",
    "        y = torch.FloatTensor(y)\n",
    "        return zx, y\n",
    "    return zx\n",
    "\n",
    "class TrueModel(nn.Module):\n",
    "\n",
    "    def __init__(self, hiddens, seed=0):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for in_dim, out_dim in zip(hiddens[:-1], hiddens[1:]):\n",
    "            layers.append(nn.Linear(in_dim, out_dim))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        layers.pop()\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "        self.loss_fn = nn.BCELoss()\n",
    "        self.optim = Adam(self.parameters())\n",
    "\n",
    "    def forward(self, zx):\n",
    "        return self.model(zx)\n",
    "\n",
    "    def predict(self, z, x):\n",
    "        zx = to_tensor(z, x)\n",
    "        pred = self(zx)\n",
    "        pred_y = pred.detach().round().cpu().numpy()\n",
    "        return pred_y\n",
    "\n",
    "    def fit(self, z, x, y, patience=10):\n",
    "        zx, y = to_tensor(z, x, y)\n",
    "\n",
    "        epoch, counter = 0, 0\n",
    "        best_loss = float('inf')\n",
    "        while True:\n",
    "            pred = self(zx)\n",
    "            loss = self.loss_fn(pred, y)\n",
    "\n",
    "            self.optim.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "            \n",
    "            epoch += 1\n",
    "            if loss.item() <= best_loss:\n",
    "                torch.save(self.state_dict(), self.path)\n",
    "                best_loss = loss.item()\n",
    "                counter = 0\n",
    "            else:\n",
    "                counter += 1\n",
    "                if counter == patience:\n",
    "                    break\n",
    "        print(f\"TrueModel Fit Done in {epoch} epochs!\")\n",
    "\n",
    "    def sample(self, s, x, scale=0.8):\n",
    "        sx = to_tensor(s, x)\n",
    "        prob = self(sx)\n",
    "        y = torch.bernoulli(prob * scale)\n",
    "        return y.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_initial_data(n, seed = 0):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    s0 = torch.bernoulli(torch.empty(n,1).uniform_(0,1)).numpy()\n",
    "    x0 = np.random.randn(n, 1) + np.sin(s0)\n",
    "    z0 = np.cos(x0) + np.random.randn(n, 1)\n",
    "    y = torch.bernoulli(torch.from_numpy(1 /(1+  np.exp(-x0 +z0))))\n",
    "    return torch.from_numpy(s0), to_tensor(x0, z0), y\n",
    "\n",
    "def sequential_data(s0, x0, y0, seq_len, hiddens, l, seed=0):\n",
    "    n = s0.size()[0]\n",
    "    model = TrueModel(hiddens, seed)\n",
    "    sx = to_tensor(s0, x0)\n",
    "    sx.requires_grad = True\n",
    "    sx = sx.to(dtype=torch.float32)\n",
    "    prob = model(sx)\n",
    "    loss = nn.BCELoss()(prob, torch.ones_like(prob))\n",
    "    loss.backward()\n",
    "    x = x0\n",
    "    y= y0\n",
    "    prevx = x.numpy()\n",
    "    prevy = y\n",
    "    s0 = s0.numpy()\n",
    "    nx = np.empty_like(s0)\n",
    "    nz = np.empty_like(s0)\n",
    "    ny = np.empty_like(s0)\n",
    "    for i in range(1, seq_len):\n",
    "        loss = nn.BCELoss()(prob, torch.ones_like(prob))\n",
    "        delta_y = prevy*loss\n",
    "        for j in range(n):\n",
    "            nx[j] = np.random.randn() + np.sin(s0[j]) + l*(prevx[j][0] - int(delta_y[j]))\n",
    "            nz[j] = np.cos(nx[j]) + np.random.randn() + l*(prevx[j][1] - int(delta_y[j]))\n",
    "        ny = torch.bernoulli(torch.from_numpy(1 /(1+  np.exp(-nx +nz))))\n",
    "        prevx = to_tensor(nx, nz)\n",
    "        x = torch.cat((x, prevx),0)\n",
    "        y = torch.cat((y, ny),0)\n",
    "        prevx = prevx.numpy()\n",
    "        prevy = ny\n",
    "    x = np.array(x, dtype=np.float32).reshape((n, seq_len, 2))\n",
    "    y = np.array(y, dtype=np.int32).reshape(n, seq_len, 1)\n",
    "    return x, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0, x0, y0 = gen_initial_data(5,0)\n",
    "x, y = sequential_data(s0, x0, y0, seq_len, hiddens, l, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10, 2)\n",
      "(5, 10, 1)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(s0.size()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7641, -1.1693],\n",
      "        [ 1.2416,  1.2733],\n",
      "        [ 0.9787,  0.4067],\n",
      "        [ 2.2409, -0.7243],\n",
      "        [ 1.8676,  0.1182]])\n",
      "[[ 1.7640524  -1.1693332 ]\n",
      " [ 1.2416282   1.2733443 ]\n",
      " [ 0.978738    0.406713  ]\n",
      " [ 2.2408931  -0.7242808 ]\n",
      " [ 1.867558    0.11817354]\n",
      " [ 0.32044882  2.2864342 ]\n",
      " [ 1.7266716   0.09376465]\n",
      " [ 0.541737    1.23116   ]\n",
      " [ 1.7181684  -0.4244255 ]\n",
      " [ 0.4998235   0.03538879]]\n"
     ]
    }
   ],
   "source": [
    "print(x0)\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.7640524   1.2416282 ]\n",
      " [ 0.978738    2.2408931 ]\n",
      " [ 1.867558   -0.13580686]\n",
      " [ 1.7915595   0.6901138 ]\n",
      " [ 0.73825216  0.41059852]\n",
      " [ 0.9855146   2.2957444 ]\n",
      " [ 0.7610377   0.12167501]\n",
      " [ 0.44386324  0.33367434]\n",
      " [ 2.33555    -0.20515826]\n",
      " [ 0.3130677  -0.85409576]]\n"
     ]
    }
   ],
   "source": [
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.7640524   1.2416282   0.978738    2.2408931   1.867558   -0.13580686\n",
      "   1.7915595   0.6901138   0.73825216  0.41059852]\n",
      " [ 0.9855146   2.2957444   0.7610377   0.12167501  0.44386324  0.33367434\n",
      "   2.33555    -0.20515826  0.3130677  -0.85409576]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s_train, s_test, x_train, x_test, y_train, y_test = train_test_split(s0, np.transpose(np.array(x, dtype=np.float32)).reshape((10000, 2, seq_len)), y, test_size=test_size, random_state=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 2, 10)\n"
     ]
    }
   ],
   "source": [
    "def visualize_data(data, label, step, sample_size=10000):\n",
    "    batch, n_dim, steps = data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
